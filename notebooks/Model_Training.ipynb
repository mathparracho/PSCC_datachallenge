{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libs\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImage,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    DivisiblePadd,\n",
    "    RandAffined,\n",
    "    RandRotated,\n",
    "    RandGaussianNoised,\n",
    "    Resized\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet, SwinUNETR\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the dataset\n",
    "\n",
    "##IMPORTANT: CHANGE HERE TO THE DATA PATH##\n",
    "# it is made with the same format as written in the cluster\n",
    "\n",
    "data_dir = \"/tsi/data_education/data_challenge\"\n",
    "train_images = sorted(glob.glob(os.path.join(data_dir, \"train/volume\", \"*.nii*\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_dir, \"train/seg\", \"*.nii*\")))\n",
    "data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "train_files, val_files = data_dicts[:-90], data_dicts[-90:] # getting aprox 1/3 of the data to validation\n",
    "print(train_images) ##check if it gets the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRANSFORMS PreProcessing\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        DivisiblePadd([\"image\", \"label\"], 16),\n",
    "        Resized(keys=[\"image\", \"label\"], spatial_size=(192,192,192)) #downsampling to 192 due the memory limits\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        DivisiblePadd([\"image\", \"label\"], 16),\n",
    "        Resized(keys=[\"image\", \"label\"],spatial_size=(192,192,192))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the datasets\n",
    "\n",
    "#batch size = 1 due to memory limitation\n",
    "train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds,num_workers=4,batch_size=1)\n",
    "\n",
    "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds,num_workers=4,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the early stopping and functions to save and load the dataset dicts\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the model instance - SwinUNETR\n",
    "\n",
    "model = SwinUNETR(img_size=(192,192,192), in_channels=1, out_channels=2, use_checkpoint=True,attn_drop_rate=0.2, dropout_path_rate=0.2,drop_rate=0.2).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 1e-4,amsgrad=True)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True,softmax = True, include_background=False)\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pytorch usual pipeline\n",
    "\n",
    "total_time = 0\n",
    "max_epochs = 10 ## The best results came from the model with 10 epochs, so if it is necessary maybe change this value\n",
    "val_interval = 2\n",
    "print_interval = 1\n",
    "epoch_loss_values = []\n",
    "losses_validation = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    start_time = datetime.now()\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train() # tell Dropout and BatchNorm to work bcs it is training\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    # getting data for each batch\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "\n",
    "        # normal pipeline\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       \n",
    "\n",
    "        #loss.item -> each batch loss\n",
    "        epoch_loss += loss.item()\n",
    "        if (epoch) % print_interval == 0:\n",
    "            print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
    "\n",
    "    # measuring time\n",
    "    actual_time = datetime.now() - start_time\n",
    "    print(f\"time to train this epoch: {actual_time}\")\n",
    "    total_time += actual_time.total_seconds()\n",
    "    # saving the loss for the actual epoch\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval() # tell Dropout and BatchNorm to \"turn off\" bcs I am evaluating the model\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0\n",
    "            counter = 1\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                #get the loss to the validation set\n",
    "                outputs = model(val_inputs)\n",
    "                loss_val += loss_function(outputs, val_labels).item()\n",
    "                print(f\"val_loss: {loss_val}\")\n",
    "\n",
    "            loss_val_avg = loss_val / len(val_loader)\n",
    "            losses_validation.append(loss_val_avg)\n",
    "            \n",
    "            print(f\"validation average loss: {loss_val_avg:.4f}\")\n",
    "            f = open(\"valLossesSWIN.txt\", \"a\")\n",
    "            f.write(f\"validation average loss: {loss_val_avg:.4f}\\n\")\n",
    "            f.close()\n",
    "\n",
    "            if early_stopper.early_stop(loss_val_avg):\n",
    "                print(\"early stopped!\")\n",
    "                break\n",
    "\n",
    "        #saving for each epoch\n",
    "        model.eval()\n",
    "        torch.save(model, \"modelSWIN.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
