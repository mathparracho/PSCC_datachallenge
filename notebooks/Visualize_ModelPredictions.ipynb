{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism \n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    DivisiblePadd,\n",
    "    RandAffined,\n",
    "    RandRotated,\n",
    "    RandGaussianNoised,\n",
    "    ToTensor,\n",
    "    Resized,\n",
    "    FillHoles,\n",
    "    RemoveSmallObjects,\n",
    "    KeepLargestConnectedComponent\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.inferers import sliding_window_inference, SimpleInferer\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from monai.networks.nets import UNet, SwinUNETR\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/tsi/data_education/data_challenge\"\n",
    "train_images = sorted(glob.glob(os.path.join(data_dir, \"train/volume\", \"*.nii*\")))\n",
    "#train_images = sorted(glob.glob(os.path.join(data_dir, \"train/lungs_seg\", \"*.nii*\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_dir, \"train/seg\", \"*.nii*\")))\n",
    "#train_labels = sorted(glob.glob(os.path.join(data_dir, \"train/lungs_seg\", \"*.nii*\")))\n",
    "data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "train_files, val_files = data_dicts[0:3], data_dicts[90:110] #no paper, ele treinou pra 16 e testou em 4\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        DivisiblePadd([\"image\", \"label\"], 16),\n",
    "        Resized(keys=[\"image\", \"label\"], spatial_size=(192,192,192))\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        DivisiblePadd([\"image\", \"label\"], 16),\n",
    "        Resized(keys=[\"image\", \"label\"], spatial_size=(192,192,192))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 images -> transform\n",
    "train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# 16 images -> transform + data augmentation\n",
    "#augm_ds= Dataset(data=train_files, transform=[train_transforms, augm_transforms])\n",
    "\n",
    "# Not declararing the batch size -> whole dataset -> 16(data) + 16(data augmentation) = 32 images per epoch\n",
    "# this means 1 batch = 32 images\n",
    "#train_ds = ConcatDataset([train_ds, augm_ds])\n",
    "\n",
    "train_loader = DataLoader(train_ds)\n",
    "\n",
    "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the model\n",
    "\n",
    "model = torch.load(\"./models/final/model15UNETFINAL.h5\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference and some PostProcessing\n",
    "\n",
    "images = []\n",
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "oneHot = AsDiscrete(threshold=0.5)\n",
    "\n",
    "for val_data in train_loader:\n",
    "    val_inputs, val_labels = (\n",
    "        val_data[\"image\"].to(device),\n",
    "        val_data[\"label\"].to(device),\n",
    "    )\n",
    "    val_labels = oneHot(val_labels)\n",
    " \n",
    "    print(\"predicting\")\n",
    "    images.append(val_inputs)\n",
    "    output = model(val_inputs)\n",
    "    \n",
    "    ############################\n",
    "    print(f\"outputShape {output.shape}\")\n",
    "    print(f\"torchargmax {torch.argmax(output.cpu(), dim=1).shape}\")\n",
    "    print(torch.argmax(output.cpu(), dim=1)[0,0,0,108])\n",
    "    print(output[:,:,0,0,0])\n",
    "\n",
    "    output = torch.argmax(output.cpu(), dim=1)\n",
    "    postProcessing2 = Compose(\n",
    "            [#AsDiscrete(threshold=0.5),\n",
    "            FillHoles(),\n",
    "            #RemoveSmallObjects(min_size=5)\n",
    "            ]\n",
    "            )\n",
    "    output = postProcessing2(output)\n",
    "\n",
    "    print(\"##############\")\n",
    "    print(f\"postprocessingMOnai {output.shape}\")\n",
    "    #print(1 in output.cpu()[:,:,108])\n",
    "    print(1 in output[0, 0, :, 108])\n",
    "    #print(output[:,:,0,0,0])\n",
    "    ###########################\n",
    "\n",
    "    outputs.append(output)\n",
    "    labels.append(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming outputs, labels, and images are your variables\n",
    "output = outputs[0]\n",
    "label = labels[0][0][0]\n",
    "image = images[0][0][0]\n",
    "\n",
    "print(\"-------\",output.shape)\n",
    "\n",
    "# Set the slice range from 45 to 50\n",
    "slice_start = 100\n",
    "slice_end = 110\n",
    "\n",
    "# Calculate the number of slices\n",
    "num_slices = slice_end - slice_start\n",
    "\n",
    "# Create a subplot with 'num_slices' rows and 3 columns\n",
    "fig, axes = plt.subplots(num_slices, 3, figsize=(15, 5 * num_slices))\n",
    "\n",
    "for i in range(num_slices):\n",
    "    # Increment the slice index\n",
    "    current_slice = slice_start + i\n",
    "    \n",
    "    # Plot the Model Output\n",
    "    #axes[i, 0].imshow(torch.argmax(output.cpu(), dim=1)[0, :, :, current_slice])\n",
    "    axes[i, 0].imshow(output[0, :, :, current_slice].cpu())\n",
    "    axes[i, 0].set_title(f'Model Output - Slice {current_slice}')\n",
    "\n",
    "    # Plot the Label\n",
    "    axes[i, 1].imshow(label.cpu()[:, :, current_slice])\n",
    "    axes[i, 1].set_title(f'Label - Slice {current_slice}')\n",
    "\n",
    "    # Plot the Input Image\n",
    "    axes[i, 2].imshow(image.cpu()[:, :, current_slice])\n",
    "    axes[i, 2].set_title(f'Input Image - Slice {current_slice}')\n",
    "\n",
    "    print(f\"salvando imagem {i}\")\n",
    "\n",
    "# Adjust layout for better visualization\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plots as PNG files\n",
    "for i in range(num_slices):\n",
    "    current_slice = slice_start + i\n",
    "    fig.savefig(f\"./slice_{current_slice}_plotSWIN.png\")\n",
    "\n",
    "# Close the figure\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
