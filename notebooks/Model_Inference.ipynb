{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libs\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    DivisiblePadd,\n",
    "    RandAffined,\n",
    "    RandRotated,\n",
    "    RandGaussianNoised,\n",
    "    ToTensor,\n",
    "    Resized,\n",
    "    FillHolesd,\n",
    "    RemoveSmallObjectsd\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.inferers import sliding_window_inference, SimpleInferer\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the dataset\n",
    "\n",
    "##IMPORTANT: CHANGE HERE TO THE DATA PATH##\n",
    "# it is made with the same format as written in the cluster\n",
    "\n",
    "test_images_dir = \"/tsi/data_education/data_challenge/test/volume\"\n",
    "\n",
    "test_images = sorted(glob.glob(os.path.join(test_images_dir,\"*.nii*\")))\n",
    "test_data = [{\"image\": image} for image in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRANSFORMS - PreProcessing & PostProcessing\n",
    "\n",
    "##IMPORTANT: CHANGE HERE TO THE PLACE YOU WANT TO SAVE THE DATA##\n",
    "\n",
    "testD_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        DivisiblePadd([\"image\"], 16),\n",
    "        Resized(keys=[\"image\"], spatial_size=(192,192,192))\n",
    "    ]\n",
    ")\n",
    "\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=testD_transforms,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "        ),\n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        FillHolesd(keys=\"pred\"),\n",
    "        SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=\"./predictionsSWIN\", output_postfix=\"\", resample=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the dataset\n",
    "\n",
    "test_org_ds = Dataset(data=test_data, transform=testD_transforms)\n",
    "test_org_loader = DataLoader(test_org_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the model\n",
    "\n",
    "##IMPORTANT: CHANGE HERE TO THE PLACE WHERE THE MODEL IS STORED#\n",
    "\n",
    "model = torch.load(\"./modelSWIN.h5\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting the inference\n",
    "\n",
    "inferer = SimpleInferer()\n",
    "model.eval()\n",
    "\n",
    "results = []\n",
    "counter = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_org_loader:\n",
    "        counter += 1\n",
    "        test_inputs = test_data[\"image\"].to(device)\n",
    "        test_data[\"pred\"] = inferer(test_inputs,  model)\n",
    "        print(f\"prediciting {counter}\")\n",
    "\n",
    "        test_data = [post_transforms(i) for i in decollate_batch(test_data)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
